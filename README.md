# Question-Answering in a Box with Self-hosted LLMs & RAG

- Setup the complete infrastructure stack for a Question-Answering chatbot for your private data in just a few minutes!
- Your stack will be powered by Self-hosted Open-Source Large Language Models and Retrieval Augmented Generation running on Kubernetes Cloud clusters.

## Install Documentation

* [Cluster Setup Summary](docs/install.md#cluster-setup-summary)
* [Install Infrastructure Tools](docs/install.md#install-infrastructure-tools)
* [Install Model Serve Stack](docs/install.md#install-model-serve-stack)
* [Model Serving](docs/install.md#model-serve)
* [Retrieval Augmented Generation using FAISS](docs/install.md#retrieval-augmented-generation-rag-using-faiss)
* [Creation of the Vector Store](docs/install.md#creation-of-the-vector-store)
* [Install the RAG & LLM querying service](docs/install.md#setup-rag--llm-service)
* [Send a question to your LLM with RAG](docs/install.md#query-the-llm-with-rag)
* [Query your LLM with RAG using a Chat UI](docs/install.md#query-the-llm-with-rag-using-a-chat-ui)
* [Uninstall](docs/install.md#uninstall)

Jump to complete install doc available [here](docs/install.md).

