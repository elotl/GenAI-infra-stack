apiVersion: apps/v1
kind: Deployment
metadata:
  name: serveragllm-deployment
  labels:
    app: modelragllmserve
    elotl-luna: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      model: serveragllm
  template:
    metadata:
      labels:
        model: serveragllm
      annotations:
        node.elotl.co/instance-type-regexp: "^t3.xlarge$"
    spec:
      containers:
        - name: serveragllm
          image: elotl/serveragllm:v1.2
          imagePullPolicy: Always
          ports:
            - containerPort: 8000
          resources:
            requests:
              cpu: "1.5"
              memory: "1G"
          env:
          - name: MODEL_LLM_SERVER_URL
            value: ${MODEL_LLM_SERVER_URL}
          - name: AWS_ACCESS_KEY_ID
            value: ${AWS_ACCESS_KEY_ID}
          - name: AWS_SECRET_ACCESS_KEY
            value: ${AWS_SECRET_ACCESS_KEY}
          - name: VECTOR_DB_S3_BUCKET
            value: ${VECTOR_DB_S3_BUCKET}
          - name: VECTOR_DB_S3_FILE
            value: ${VECTOR_DB_S3_FILE}
          - name: MODEL_ID
            value: ${MODEL_ID}
          - name: MAX_TOKENS
            value: ${MAX_TOKENS}
          - name: MODEL_TEMPERATURE
            value: ${MODEL_TEMPERATURE}
          - name: RELEVANT_DOCS
            value: ${RELEVANT_DOCS}
---
apiVersion: v1
kind: Service
metadata:
  name: serveragllm-service
  labels:
    app: modelragllmserve
spec:
  type: LoadBalancer
  selector:
    model: serveragllm
  ports:
    - name: http
      port: 80
      targetPort: 8000
